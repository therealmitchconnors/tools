apiVersion: v1
kind: ServiceAccount
metadata:
  name: config-change-service-account
  namespace: {{ .Release.Namespace }}
  labels:
    app: config-change
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: config-change-{{ .Release.Namespace }}
rules:
- apiGroups: ["config.istio.io"]
  resources: ["*"]
  verbs: ["*"]
- apiGroups: ["rbac.istio.io"]
  resources: ["*"]
  verbs: ["get", "watch", "list"]
- apiGroups: ["networking.istio.io"]
  resources: ["*"]
  verbs: ["*"]
- apiGroups: ["authentication.istio.io"]
  resources: ["*"]
  verbs: ["*"]
- apiGroups: ["apiextensions.k8s.io"]
  resources: ["customresourcedefinitions"]
  verbs: ["*"]
- apiGroups: ["extensions"]
  resources: ["thirdpartyresources", "thirdpartyresources.extensions", "ingresses", "ingresses/status", "deployments", "deployments/scale"]
  verbs: ["*"]
- apiGroups: ["apps"]
  resources: ["deployments", "deployments/scale"]
  verbs: ["*"]
- apiGroups: [""]
  resources: ["configmaps", "endpoints", "pods", "services", "namespaces", "secrets", "replicationcontrollers"]
  verbs: ["create", "get", "list", "watch", "update", "patch"]
- apiGroups: [""]
  resources: ["endpoints", "pods", "services"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["namespaces", "nodes", "secrets"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: config-change-{{ .Release.Namespace }}
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: config-change-{{ .Release.Namespace }}
subjects:
  - kind: ServiceAccount
    name: config-change-service-account
    namespace: {{ .Release.Namespace }}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-scaler
  namespace: {{ .Release.Namespace }}
spec:
  # The job takes on average 5 mins to complete, scaling 20 deployments with a 10-20s sleep in between
  # We schedule the job for every 10min, giving us 5min on/off
  replicas: 0
  selector:
    matchLabels:  
      deployment: scaler
  template:
    metadata:
      labels:
        deployment: scaler
    spec:
      containers:
      - name: scaler
        image: istio/kubectl:1.3.0
        args:
        - bash
        - -c
        - |-
          set -x
          while sleep 1; do
            ns=$(kubectl get ns -l scenario=many-svc -o name | sed 's/namespace\///g' | shuf -n 1 -)
            avgscale=$(kubectl get deployment -n $ns {{ $.Values.serviceName }} -o jsonpath='{.metadata.labels.avgscale}')
            range=$(kubectl get deployment -n $ns {{ $.Values.serviceName }} -o jsonpath='{.metadata.labels.scalerange}')
            replicas=$((RANDOM%range+avgscale-range/2))
            echo "scaling $ns to $replicas"
            kubectl scale deployment loadservice -n $ns --replicas $replicas
          done
      - name: labeler
        image: istio/kubectl:1.3.0
        args:
        - bash
        - -c
        - |-
          set -x
          while sleep 60; do
            ns=$(kubectl get ns -l scenario=many-svc -o name | sed 's/namespace\///g' | shuf -n 1 -)
            configgroup=$(kubectl get namespace $ns -o jsonpath='{.metadata.labels.config-group}')
            oldpolicygroup=$(kubectl get namespace $ns -o jsonpath='{.metadata.labels.policy-group}')
            if [ -z "${oldpolicygroup}" ]; then 
              oldpolicygroup=$((RANDOM%3))
            fi
            newpolicygroup=$((RANDOM%2))
            if ["$newpolicygroup" -gte "$oldpolicygroup"]; then
              newpolicygroup=$((newpolicygroup+1))
            fi
            echo "relabeling $ns to policy-group $newpolicygroup"
            kubectl label ns $ns --overwrite policy-group=$newpolicygroup
          done
      serviceAccountName: config-change-service-account
---
{{ if $.Values.ciliumL4 }}
apiVersion: "cilium.io/v2"
kind: CiliumClusterwideNetworkPolicy
metadata:
  name: cilium-namespaces
spec:
  endpointSelector:
    matchLabels:
      app: fortio-client
  ingress:
  - fromEndpoints:
    - matchLabels:
        app: fortio-commander
    toPorts:
    - ports:
      - port: "8080"
        protocol: TCP
---
apiVersion: "cilium.io/v2"
kind: CiliumClusterwideNetworkPolicy
metadata:
  name: between-tests
spec:
  endpointSelector:
    matchLabels:
      k8s:io.cilium.k8s.namespace.labels.policy-group: "3"
  egress:
  - toEndpoints:
    - matchLabels:
        k8s:io.cilium.k8s.namespace.labels.policy-group: "1"
    - matchLabels:
        k8s:io.cilium.k8s.namespace.labels.policy-group: "2"
---
{{ end }}